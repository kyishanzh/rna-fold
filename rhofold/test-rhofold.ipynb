{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: importing 'simtk.openmm' is deprecated.  Import 'openmm' instead.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from rhofold.data.balstn import BLASTN\n",
    "from rhofold.rhofold import RhoFold\n",
    "from rhofold.config import rhofold_config\n",
    "from rhofold.utils import get_device, save_ss2ct, timing\n",
    "from rhofold.relax.relax import AmberRelaxation\n",
    "from rhofold.utils.alphabet import get_features\n",
    "\n",
    "def seq_id_to_embedding(seq_id):\n",
    "    \"\"\"\n",
    "    Get Evo2 embeddings for a given sequence ID from a .pt file\n",
    "    \"\"\"\n",
    "    embeddings_dir = \"/home/user/rna-fold/data/RNA3D_DATA/evo2_embeddings\"\n",
    "    file_path = os.path.join(embeddings_dir, f\"{seq_id}.pt\")\n",
    "    \n",
    "    if os.path.exists(file_path):\n",
    "        return torch.load(file_path)\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Embedding file for {seq_id} not found at {file_path}\")\n",
    "\n",
    "@torch.no_grad()\n",
    "def main(ckpt='./pretrained/RhoFold_pretrained.pt'):\n",
    "    model = RhoFold(rhofold_config)\n",
    "    model.load_state_dict(torch.load(ckpt, map_location=torch.device('cpu'))['model'], strict=False)\n",
    "    model.eval()\n",
    "\n",
    "    return model\n",
    "\n",
    "def inference(seq_id='165d_B', normal_inf=False):\n",
    "    device = get_device('cpu')\n",
    "    model = main().to(device)\n",
    "    print(\"Number of params:\", sum(p.numel() for p in model.parameters()))\n",
    "    input_fas = f'../data/RNA3D_DATA/seq/{seq_id}.seq'\n",
    "    input_a3m = f'../data/RNA3D_DATA/rMSA/{seq_id}.a3m'\n",
    "    data_dict = get_features(input_fas, input_a3m)\n",
    "    embedding = seq_id_to_embedding(seq_id).to(torch.float32)\n",
    "\n",
    "    outputs = model(tokens=data_dict['tokens'].to(device),\n",
    "                    rna_fm_tokens=data_dict['rna_fm_tokens'].to(device),\n",
    "                    seq=data_dict['seq'],\n",
    "                    evo2_fea=embedding if not normal_inf else None,\n",
    "                    )\n",
    "\n",
    "    output = outputs[-1]\n",
    "\n",
    "    unrelaxed_model = f'tmp/unrelaxed_model.pdb'\n",
    "\n",
    "    node_cords_pred = output['cord_tns_pred'][-1].squeeze(0)\n",
    "    model.structure_module.converter.export_pdb_file(data_dict['seq'],\n",
    "                                                        node_cords_pred.data.cpu().numpy(),\n",
    "                                                        path=unrelaxed_model, chain_id=None,\n",
    "                                                        confidence=output['plddt'][0].data.cpu().numpy())\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "openfold_path = os.path.abspath(os.path.join(\"..\", \"openfold\"))\n",
    "if openfold_path not in sys.path:\n",
    "    sys.path.insert(0, openfold_path)\n",
    "from typing import Optional, Union, Dict, Tuple\n",
    "\n",
    "# PDB parser\n",
    "from Bio.PDB import PDBParser\n",
    "\n",
    "# openfold utilities\n",
    "from openfold.utils.rigid_utils import Rigid, Rotation\n",
    "from openfold.utils.loss import compute_fape, AlphaFoldLoss\n",
    "import ml_collections\n",
    "\n",
    "def compute_fape_from_output(\n",
    "    output: Dict[str, torch.Tensor],\n",
    "    pdb_path: str,\n",
    "    chain_id: Optional[str] = None,\n",
    "    length_scale: float = 10.0,\n",
    "    l1_clamp_distance: Optional[float] = None,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Compute a single‐scalar FAPE loss between RhoFold model output and a ground-truth RNA PDB.\n",
    "\n",
    "    Args:\n",
    "        output: RhoFold model output dict containing 'frames' and \"cords_c1'\" keys.\n",
    "        pdb_path: path to the ground-truth RNA PDB file.\n",
    "        chain_id: which chain in the PDB to use; if None, picks the first.\n",
    "        length_scale: FAPE length‐scale (Å) divisor.\n",
    "        l1_clamp_distance: if set, clamps distances above this value.\n",
    "\n",
    "    Returns:\n",
    "        A differentiable scalar torch.Tensor.\n",
    "    \"\"\"\n",
    "    # 1) Extract predicted frames\n",
    "    pred_frames_tensor = output[\"frames\"]\n",
    "    \n",
    "    # Handle the dimensions appropriately\n",
    "    if isinstance(pred_frames_tensor, list):\n",
    "        pred_frames_tensor = pred_frames_tensor[-1]  # Take last element if list\n",
    "    \n",
    "    # Extract the last recycle frame if there's a recycle dimension\n",
    "    if pred_frames_tensor.dim() == 4:  # [recycle, batch, N, 7]\n",
    "        pred_frames_tensor = pred_frames_tensor[-1]  # [batch, N, 7]\n",
    "    \n",
    "    # Remove batch dim if batch=1\n",
    "    if pred_frames_tensor.dim() == 3 and pred_frames_tensor.shape[0] == 1:\n",
    "        pred_frames_tensor = pred_frames_tensor.squeeze(0)  # [N, 7]\n",
    "    \n",
    "    # Convert to Rigid object\n",
    "    pred_frames = Rigid.from_tensor_7(pred_frames_tensor)\n",
    "    \n",
    "    # Extract predicted C1' positions\n",
    "    pred_c1_positions = output[\"cords_c1'\"][-1].squeeze(0)  # Shape [N, 3]\n",
    "    \n",
    "    # 2) Parse the PDB to get ground truth C1' positions\n",
    "    parser = PDBParser(QUIET=True)\n",
    "    structure = parser.get_structure(\"gt\", pdb_path)\n",
    "    if chain_id is None:\n",
    "        chain = next(structure.get_chains())\n",
    "    else:\n",
    "        chain = structure[0][chain_id]\n",
    "    \n",
    "    # Extract C1' atoms from the PDB structure\n",
    "    gt_c1_positions = []\n",
    "    for res in chain:\n",
    "        if \"C1'\" in res:\n",
    "            gt_c1_positions.append(res[\"C1'\"].get_coord())\n",
    "    \n",
    "    assert len(gt_c1_positions) == pred_c1_positions.shape[0]\n",
    "    \n",
    "    # Convert to tensor with same dtype and device as predictions\n",
    "    dtype = pred_frames_tensor.dtype\n",
    "    device = pred_frames_tensor.device\n",
    "    gt_c1_positions = torch.tensor(gt_c1_positions, dtype=dtype, device=device)\n",
    "    \n",
    "    # Create same-length arrays (truncate if necessary)\n",
    "    n_residues = min(pred_c1_positions.shape[0], gt_c1_positions.shape[0])\n",
    "    pred_c1_positions = pred_c1_positions[:n_residues]\n",
    "    gt_c1_positions = gt_c1_positions[:n_residues]\n",
    "    pred_frames = pred_frames[:n_residues]\n",
    "    \n",
    "    # Create a mask for the positions (all 1s since we've truncated to match)\n",
    "    mask = torch.ones(n_residues, device=device)\n",
    "    \n",
    "    # 3) Create target frames\n",
    "    # For RNA, we'll create an identity rotation frame with C1' positions as translations\n",
    "    # Create identity quaternions: [w, x, y, z] with w=1, x,y,z=0\n",
    "    zeros = torch.zeros(n_residues, 3, device=device, dtype=dtype)\n",
    "    ones = torch.ones(n_residues, 1, device=device, dtype=dtype)\n",
    "    quats = torch.cat([ones, zeros], dim=-1)\n",
    "    \n",
    "    # Create target frames with identity rotations and ground truth C1' positions\n",
    "    target_frames = Rigid(\n",
    "        Rotation(quats=quats, rot_mats=None),\n",
    "        gt_c1_positions\n",
    "    )\n",
    "    \n",
    "    # 4) Compute FAPE\n",
    "    fape = compute_fape(\n",
    "        pred_frames=pred_frames,\n",
    "        target_frames=target_frames,\n",
    "        frames_mask=mask,\n",
    "        pred_positions=pred_c1_positions,\n",
    "        target_positions=gt_c1_positions,\n",
    "        positions_mask=mask,\n",
    "        length_scale=length_scale,\n",
    "        pair_mask=None,\n",
    "        l1_clamp_distance=l1_clamp_distance,\n",
    "    )\n",
    "    \n",
    "    return fape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of params: 130059855\n",
      "Number of params: 130059855\n"
     ]
    }
   ],
   "source": [
    "seq_id = '8psh_B'\n",
    "normal_output = inference(seq_id=seq_id, normal_inf=True)\n",
    "special_output = inference(seq_id=seq_id, normal_inf=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence length: 8\n"
     ]
    }
   ],
   "source": [
    "print(\"Sequence length:\", normal_output[\"plddt\"][0].shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.conda/envs/rhofold/lib/python3.7/site-packages/ipykernel_launcher.py:75: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1640811797118/work/torch/csrc/utils/tensor_new.cpp:201.)\n"
     ]
    }
   ],
   "source": [
    "normal_L = compute_fape_from_output(normal_output, f\"../data/RNA3D_DATA/pdb/{seq_id}.pdb\")\n",
    "special_L = compute_fape_from_output(special_output, f\"../data/RNA3D_DATA/pdb/{seq_id}.pdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.9983, grad_fn=<DivBackward0>)\n",
      "tensor(2.9983, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(special_L)\n",
    "print(normal_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6061], grad_fn=<MeanBackward1>)\n",
      "tensor([0.6061], grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print(special_output[\"plddt\"][1])\n",
    "print(normal_output[\"plddt\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['frames',\n",
       " 'unnormalized_angles',\n",
       " 'angles',\n",
       " 'single',\n",
       " 'cord_tns_pred',\n",
       " \"cords_c1'\",\n",
       " 'plddt',\n",
       " 'ss',\n",
       " 'p',\n",
       " 'c4_',\n",
       " 'n']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(normal_output.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_L.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  0.4549,   0.1827,   0.3823,  -0.7833,   4.3325,  10.6797,  -0.9257],\n",
       "         [  0.6294,   0.4387,   0.3185,  -0.5568,   2.1081,   5.0937,   3.0105],\n",
       "         [  0.7294,   0.5880,   0.2750,  -0.2158,  -0.5881,  -1.5042,   4.5593],\n",
       "         [  0.7802,   0.5562,   0.2772,   0.0714,  -0.3522,  -7.9385,   2.5301],\n",
       "         [  0.8623,   0.2562,   0.2818,   0.3339,  -0.7047, -12.9255,   1.7130],\n",
       "         [  0.6348,  -0.6304,  -0.4455,  -0.0342,  -0.9307,  -7.9234,  -5.4222],\n",
       "         [  0.6770,  -0.7215,  -0.0331,   0.1413,  -5.5291,  -2.1601,  -2.5444],\n",
       "         [  0.5620,  -0.7495,   0.2591,   0.2351,  -6.6236,   6.9702,   0.2256],\n",
       "         [  0.5077,   0.5388,  -0.2539,   0.6225,  -0.9057,   5.7893,  -5.3306]]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_output[\"frames\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  0.4549,   0.1827,   0.3823,  -0.7833,   4.3326,  10.6789,  -0.9256],\n",
       "         [  0.6294,   0.4387,   0.3185,  -0.5568,   2.1084,   5.0929,   3.0104],\n",
       "         [  0.7294,   0.5880,   0.2750,  -0.2158,  -0.5878,  -1.5046,   4.5585],\n",
       "         [  0.7802,   0.5562,   0.2772,   0.0713,  -0.3519,  -7.9391,   2.5294],\n",
       "         [  0.8623,   0.2562,   0.2818,   0.3338,  -0.7046, -12.9258,   1.7119],\n",
       "         [  0.6348,  -0.6304,  -0.4455,  -0.0342,  -0.9306,  -7.9234,  -5.4226],\n",
       "         [  0.6770,  -0.7215,  -0.0331,   0.1413,  -5.5289,  -2.1602,  -2.5448],\n",
       "         [  0.5620,  -0.7495,   0.2591,   0.2351,  -6.6234,   6.9700,   0.2253],\n",
       "         [  0.5077,   0.5388,  -0.2539,   0.6225,  -0.9059,   5.7885,  -5.3302]]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "special_output[\"frames\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[  7.5441,   8.0379,   3.7535],\n",
       "          [  3.7557,   4.4225,   5.5446],\n",
       "          [  1.0021,  -0.6748,   5.1964],\n",
       "          [  0.7398,  -5.7531,   3.2155],\n",
       "          [  1.4135, -10.5815,   2.6508],\n",
       "          [  0.2612,  -6.4298,  -3.9785],\n",
       "          [ -2.8647,  -0.6457,  -1.4059],\n",
       "          [ -2.6314,   4.8960,   1.4187],\n",
       "          [ -0.1994,   7.6226,   1.2691]]], grad_fn=<UnsqueezeBackward0>)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[\"cords_c1'\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1, 9, 7])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[\"frames\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1, 9, 7])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['frames'].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rhofold",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
